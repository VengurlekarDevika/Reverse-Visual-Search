{
  "cells": [
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "9DYQfsUH96nl"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qucx1AwQSgI2",
        "outputId": "cd6084d3-52aa-436b-a568-ca8b74df4b33"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive/\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive/')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "QDVHbNHgmSp5"
      },
      "outputs": [],
      "source": [
        "from pandas.core.indexes.api import InvalidIndexError\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns \n",
        "import matplotlib.pyplot as plt\n",
        "import cv2\n",
        "import os\n",
        "import requests\n",
        "import torch\n",
        "import argparse\n",
        "import torchvision\n",
        "from numpy import expand_dims\n",
        "from tensorflow.keras.utils import load_img\n",
        "from keras.models import load_model\n",
        "from tensorflow.keras.utils import img_to_array\n",
        "from matplotlib import pyplot\n",
        "from matplotlib.patches import Rectangle\n",
        "from torchvision import transforms\n",
        "#import pickle\n",
        "#import torch.nn as nn\n",
        "from torchvision.models import detection\n",
        "import torchvision.models as models\n",
        "import torchvision.transforms as transforms\n",
        "#from torch.autograd import Variable\n",
        "#from sklearn.metrics import jaccard_similarity_score\n",
        "from scipy import spatial\n",
        "#from sklearn.decomposition import PCA as RandomizedPCA\n",
        "from PIL import Image\n",
        "import glob\n",
        "#pd.set_option('display.max_columns', None)\n",
        "from google.colab.patches import cv2_imshow"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "JRoUeRJoTlqa"
      },
      "outputs": [],
      "source": [
        "root_path = 'gdrive/My Drive/coco_minitrain_25k/' "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e19fJRCLlZXu"
      },
      "outputs": [],
      "source": [
        "#Displaying a single image from the folder that contains the images of Class Person\n",
        "image = plt.imread('/content/gdrive/MyDrive/coco_minitrain_25k /images/images_person/000000104747.jpg')\n",
        "plt.imshow(image)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "swY92NPTb8Az"
      },
      "outputs": [],
      "source": [
        "!pip install tensorflow"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3ABmb1fMXbXd"
      },
      "source": [
        "**OBJECT DETECTION USING THE YOLOV3 MODEL**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oGrBhwm6XmJK"
      },
      "source": [
        "**Performing object detection using two models namely YOLOv3 and Faster RCNN. The feature extraction and the similarity search is done on the basis of the Faster RCNN model.**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fspR8g69adR-"
      },
      "outputs": [],
      "source": [
        "# Performing Object Detection bu using YOLOV3 model\n",
        "\n",
        "import numpy as np\n",
        "from numpy import expand_dims\n",
        "from tensorflow.keras.utils import load_img\n",
        "from keras.models import load_model\n",
        "from tensorflow.keras.utils import img_to_array\n",
        "from matplotlib import pyplot\n",
        "from matplotlib.patches import Rectangle\n",
        " \n",
        "class BoundBox:\n",
        "\tdef __init__(self, xmin, ymin, xmax, ymax, objness = None, classes = None):\n",
        "\t\tself.xmin = xmin\n",
        "\t\tself.ymin = ymin\n",
        "\t\tself.xmax = xmax\n",
        "\t\tself.ymax = ymax\n",
        "\t\tself.objness = objness\n",
        "\t\tself.classes = classes\n",
        "\t\tself.label = -1\n",
        "\t\tself.score = -1\n",
        " \n",
        "\tdef get_label(self):\n",
        "\t\tif self.label == -1:\n",
        "\t\t\tself.label = np.argmax(self.classes)\n",
        " \n",
        "\t\treturn self.label\n",
        " \n",
        "\tdef get_score(self):\n",
        "\t\tif self.score == -1:\n",
        "\t\t\tself.score = self.classes[self.get_label()]\n",
        " \n",
        "\t\treturn self.score\n",
        " \n",
        "def _sigmoid(x):\n",
        "\treturn 1. / (1. + np.exp(-x))\n",
        " \n",
        "def decode_netout(netout, anchors, obj_thresh, net_h, net_w):\n",
        "\tgrid_h, grid_w = netout.shape[:2]\n",
        "\tnb_box = 3\n",
        "\tnetout = netout.reshape((grid_h, grid_w, nb_box, -1))\n",
        "\tnb_class = netout.shape[-1] - 5\n",
        "\tboxes = []\n",
        "\tnetout[..., :2]  = _sigmoid(netout[..., :2])\n",
        "\tnetout[..., 4:]  = _sigmoid(netout[..., 4:])\n",
        "\tnetout[..., 5:]  = netout[..., 4][..., np.newaxis] * netout[..., 5:]\n",
        "\tnetout[..., 5:] *= netout[..., 5:] > obj_thresh\n",
        " \n",
        "\tfor i in range(grid_h*grid_w):\n",
        "\t\trow = i / grid_w\n",
        "\t\tcol = i % grid_w\n",
        "\t\tfor b in range(nb_box):\n",
        "\t\t\tobjectness = netout[int(row)][int(col)][b][4]\n",
        "\t\t\tif(objectness.all() <= obj_thresh): continue\n",
        "\t\t\t# The first 4 elements are x, y, w, and h\n",
        "\t\t\tx, y, w, h = netout[int(row)][int(col)][b][:4]\n",
        "\t\t\tx = (col + x) / grid_w \n",
        "\t\t\ty = (row + y) / grid_h \n",
        "\t\t\tw = anchors[2 * b + 0] * np.exp(w) / net_w \n",
        "\t\t\th = anchors[2 * b + 1] * np.exp(h) / net_h \n",
        "\t\t\t# Class Probabilities\n",
        "\t\t\tclasses = netout[int(row)][col][b][5:]\n",
        "\t\t\tbox = BoundBox(x-w/2, y-h/2, x+w/2, y+h/2, objectness, classes)\n",
        "\t\t\tboxes.append(box)\n",
        "\treturn boxes\n",
        " \n",
        "def correct_yolo_boxes(boxes, image_h, image_w, net_h, net_w):\n",
        "\tnew_w, new_h = net_w, net_h\n",
        "\tfor i in range(len(boxes)):\n",
        "\t\tx_offset, x_scale = (net_w - new_w)/2./net_w, float(new_w)/net_w\n",
        "\t\ty_offset, y_scale = (net_h - new_h)/2./net_h, float(new_h)/net_h\n",
        "\t\tboxes[i].xmin = int((boxes[i].xmin - x_offset) / x_scale * image_w)\n",
        "\t\tboxes[i].xmax = int((boxes[i].xmax - x_offset) / x_scale * image_w)\n",
        "\t\tboxes[i].ymin = int((boxes[i].ymin - y_offset) / y_scale * image_h)\n",
        "\t\tboxes[i].ymax = int((boxes[i].ymax - y_offset) / y_scale * image_h)\n",
        " \n",
        "\n",
        "def _interval_overlap(interval_a, interval_b):\n",
        "\tx1, x2 = interval_a\n",
        "\tx3, x4 = interval_b\n",
        "\tif x3 < x1:\n",
        "\t\tif x4 < x1:\n",
        "\t\t\treturn 0\n",
        "\t\telse:\n",
        "\t\t\treturn min(x2,x4) - x1\n",
        "\telse:\n",
        "\t\tif x2 < x3:\n",
        "\t\t\t return 0\n",
        "\t\telse:\n",
        "\t\t\treturn min(x2,x4) - x3\n",
        "\n",
        "\n",
        "def bbox_iou(box1, box2):\n",
        "\tintersect_w = _interval_overlap([box1.xmin, box1.xmax], [box2.xmin, box2.xmax])\n",
        "\tintersect_h = _interval_overlap([box1.ymin, box1.ymax], [box2.ymin, box2.ymax])\n",
        "\tintersect = intersect_w * intersect_h\n",
        "\tw1, h1 = box1.xmax-box1.xmin, box1.ymax-box1.ymin\n",
        "\tw2, h2 = box2.xmax-box2.xmin, box2.ymax-box2.ymin\n",
        "\tunion = w1*h1 + w2*h2 - intersect\n",
        "\treturn float(intersect) / union\n",
        " \n",
        "def do_nms(boxes, nms_thresh):\n",
        "\tif len(boxes) > 0:\n",
        "\t\tnb_class = len(boxes[0].classes)\n",
        "\telse:\n",
        "\t\treturn\n",
        "\tfor c in range(nb_class):\n",
        "\t\tsorted_indices = np.argsort([-box.classes[c] for box in boxes])\n",
        "\t\tfor i in range(len(sorted_indices)):\n",
        "\t\t\tindex_i = sorted_indices[i]\n",
        "\t\t\tif boxes[index_i].classes[c] == 0: continue\n",
        "\t\t\tfor j in range(i+1, len(sorted_indices)):\n",
        "\t\t\t\tindex_j = sorted_indices[j]\n",
        "\t\t\t\tif bbox_iou(boxes[index_i], boxes[index_j]) >= nms_thresh:\n",
        "\t\t\t\t\tboxes[index_j].classes[c] = 0\n",
        " \n",
        "# Loading an image\n",
        "filename=\"/content/gdrive/MyDrive/coco_minitrain_25k /images/images_person/000000104747.jpg\"\n",
        "\n",
        "def load_image_pixels(filename, shape):\n",
        "\timage = load_img(filename)\n",
        "  #newsize=(800,800)\n",
        "  #image=image.resize(newsize)\n",
        "\twidth, height = image.size\n",
        "\timage = load_img(filename, target_size=shape)\n",
        "\timage = img_to_array(image)\n",
        "\timage = image.astype('float32')\n",
        "\timage /= 255.0\n",
        "\timage = expand_dims(image, 0)\n",
        "\treturn image, width, height\n",
        " \n",
        "# The results above a threshold\n",
        "def get_boxes(boxes, labels, thresh):\n",
        "\tv_boxes, v_labels, v_scores = list(), list(), list()\n",
        "\tfor box in boxes:\n",
        "\t\tfor i in range(len(labels)):\n",
        "\t\t\t# Checking if the threshold value for the label is high enough\n",
        "\t\t\tif box.classes[i] > thresh:\n",
        "\t\t\t\tv_boxes.append(box)\n",
        "\t\t\t\tv_labels.append(labels[i])\n",
        "\t\t\t\tv_scores.append(box.classes[i]*100)\n",
        "\treturn v_boxes, v_labels, v_scores\n",
        " \n",
        "# Drawing the bounding boxes around the objects detected\n",
        "def draw_boxes(filename, v_boxes, v_labels, v_scores):\n",
        "\tdata = pyplot.imread(filename)\n",
        "\tpyplot.imshow(data)\n",
        "\tax = pyplot.gca()\n",
        "\t# Plotting each bounding box\n",
        "\tfor i in range(len(v_boxes)):\n",
        "\t\tbox = v_boxes[i]\n",
        "\t\ty1, x1, y2, x2 = box.ymin, box.xmin, box.ymax, box.xmax\n",
        "\t\twidth, height = x2 - x1, y2 - y1\n",
        "\t\trect = Rectangle((x1, y1), width, height, fill=False, color='blue')\n",
        "\t\tax.add_patch(rect)\n",
        "\t\tlabel = \"%s (%.3f)\" % (v_labels[i], v_scores[i])\n",
        "\t\tpyplot.text(x1, y1, label, color='yellow')\n",
        "\tpyplot.show()\n",
        " \n",
        "# Loading the yolov3 model\n",
        "model = load_model('/content/gdrive/MyDrive/coco_minitrain_25k /images/yolo.h5')\n",
        "input_w, input_h = 416,416\n",
        "photo_filename = '/content/gdrive/MyDrive/coco_minitrain_25k /images/images_person/000000104747.jpg'\n",
        "image, image_w, image_h = load_image_pixels(photo_filename, (input_w, input_h))\n",
        "# Making prediction\n",
        "yhat = model.predict(image)\n",
        "print([a.shape for a in yhat])\n",
        "# Defining the anchors\n",
        "anchors = [[116,90, 156,198, 373,326], [30,61, 62,45, 59,119], [10,13, 16,30, 33,23]]\n",
        "\n",
        "# Defining the probability threshold for the detected objects\n",
        "class_threshold = 0.6\n",
        "boxes = list()\n",
        "for i in range(len(yhat)):\n",
        "\tboxes += decode_netout(yhat[i][0], anchors[i], class_threshold, input_h, input_w)\n",
        "correct_yolo_boxes(boxes, image_h, image_w, input_h, input_w)\n",
        "\n",
        "# Suppressing the  non-maximal boxes\n",
        "do_nms(boxes, 0.5)\n",
        "\n",
        "# Defining the labels to be detected in an image\n",
        "labels = [\"person\"]\n",
        "\n",
        "v_boxes, v_labels, v_scores = get_boxes(boxes, labels, class_threshold)\n",
        "\n",
        "for i in range(len(v_boxes)):\n",
        "\tprint(v_labels[i], v_scores[i])\n",
        "\n",
        "#Plotting the bounding box, mentioning the label and the score of the detected object\n",
        "draw_boxes(photo_filename, v_boxes, v_labels, v_scores)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uiDOdDU1exwh"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UHNuITDQJ6db"
      },
      "source": [
        "**LOADING A PRETRAINED FASTER RCNN MODEL TO PERFORM OBJECT DETECTION AND EXTRACTING THE BOUNDING BOXES**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XZXeXzMPJt5N"
      },
      "outputs": [],
      "source": [
        "from torchvision.models.detection.faster_rcnn import FastRCNNPredictor\n",
        "\n",
        "model = torchvision.models.detection.fasterrcnn_resnet50_fpn(pretrained=True, pretrained_backbone=True)\n",
        "model.eval()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CdCmovoGlZnF"
      },
      "outputs": [],
      "source": [
        "url = 'https://tech.amikelive.com/node-718/what-object-categories-labels-are-in-coco-dataset/'\n",
        "html = requests.get(url).content\n",
        "df_data= pd.read_html(html)\n",
        "\n",
        "cls = df_data[0][['ID','Object (2017 Rel.)']]\n",
        "colors = np.random.uniform(0, 255, size=(len(cls), 3))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6ednkY5F8wXt"
      },
      "outputs": [],
      "source": [
        "img = cv2.imread(\"/content/gdrive/My Drive/coco_minitrain_25k /images/images_person/000000104747.jpg\")\n",
        "img = cv2.resize(img,(400,400))\n",
        "copy_img = img.copy()\n",
        "img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "img = img.transpose((2, 0, 1))\n",
        "img = np.expand_dims(img, axis=0)\n",
        "img = img / 255.0\n",
        "img= torch.FloatTensor(img)\n",
        "img_detect = model(img)[0]\n",
        "\n",
        "img_detect"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3c-fMFcBCxRt"
      },
      "source": [
        "**DISPLAYING AN IMAGE WITH BOUNDING BOX USING A FASTER RCNN PRETRAINED MODEL**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LZF-y_PL8wjI"
      },
      "outputs": [],
      "source": [
        "for j in range(0, len(img_detect[\"boxes\"])):\n",
        "\tconfid = img_detect[\"scores\"][j]\n",
        "\tif confid >.90 and int(img_detect[\"labels\"][j])==1:\n",
        "\t\tidx = int(img_detect[\"labels\"][j])\n",
        "\t\tbox = img_detect[\"boxes\"][j].detach().cpu().numpy()\n",
        "\t\t(sX, sY, lX, lY) = box.astype(\"int\")\n",
        "\n",
        "\t\tlabel = \"{}: {:.2f}%\".format(list(cls[cls.ID==idx]['Object (2017 Rel.)'].values)[0], confid * 100)\n",
        "\t\tprint(label)\n",
        "\t\tcv2.rectangle(copy_img, (sX, sY), (lX, lY),colors[idx], 2)\n",
        "\t\tcv2_imshow(cv2.resize(copy_img[sY:lY,sX:lX],(50,50)))\n",
        "cv2_imshow(copy_img)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q42urZW91HHy"
      },
      "source": [
        "**CALCULATING IOU VALUE FOR AN IMAGE**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6SszLtFdwKcJ"
      },
      "outputs": [],
      "source": [
        "img = cv2.imread(\"/content/gdrive/MyDrive/coco_minitrain_25k /images/images_person/000000021895.jpg\")\n",
        "plt.imshow(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))\n",
        "\n",
        "# Creating a bounding box for an image\n",
        "first_bb_points = [[250, 210], [440, 210], [440, 390], [250, 390]]\n",
        "stencil = np.zeros(img.shape).astype(img.dtype)\n",
        "contours = [np.array(first_bb_points)]\n",
        "color = [255, 255, 255]\n",
        "cv2.fillPoly(stencil, contours, color)\n",
        "result1 = cv2.bitwise_and(img, stencil)\n",
        "result1 = cv2.cvtColor(result1, cv2.COLOR_BGR2RGB)\n",
        "plt.imshow(result1)\n",
        "\n",
        "# Second bounding box\n",
        "second_bb_points = [[280, 190], [438, 190], [438, 390], [280, 390]]\n",
        "stencil = np.zeros(img.shape).astype(img.dtype)\n",
        "contours = [np.array(second_bb_points)]\n",
        "color = [255, 255, 255]\n",
        "cv2.fillPoly(stencil, contours, color)\n",
        "result2 = cv2.bitwise_and(img, stencil)\n",
        "result2 = cv2.cvtColor(result2, cv2.COLOR_BGR2RGB)\n",
        "plt.imshow(result2)\n",
        "\n",
        "# IoU calculation\n",
        "intersection = np.logical_and(result1, result2)\n",
        "union = np.logical_or(result1, result2)\n",
        "iou_score = np.sum(intersection) / np.sum(union)\n",
        "print('IoU is: ', iou_score)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zWP6wB2dEbBW"
      },
      "outputs": [],
      "source": [
        "img_path = '/content/gdrive/MyDrive/coco_minitrain_25k /images/images_person'\n",
        "list_person = glob.glob(os.path.join(img_path, \"*.jpg\"))\n",
        "df_person = pd.DataFrame(columns = ['boxes','labels','scores','Image_name','object_feature_tensor'])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9XDSY5kyEbOi"
      },
      "outputs": [],
      "source": [
        "p=0\n",
        "for i in list_person:\n",
        "  img = cv2.imread(i)\n",
        "  img = cv2.resize(img,(300,300))\n",
        "  copy_img = img.copy()\n",
        "  img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "  img = img.transpose((2, 0, 1))\n",
        "  img = np.expand_dims(img, axis=0)\n",
        "  img = img / 255.0\n",
        "  img = torch.FloatTensor(img)\n",
        "  img_detect = model(img)[0]\n",
        "  for keys in img_detect:\n",
        "    img_detect[keys] = img_detect[keys].tolist()\n",
        "  t =  pd.DataFrame.from_dict(img_detect)\n",
        "  t['Image_name'] = i.split(\"/\")[-1]\n",
        "  t = t[(t.labels==1) & (t.scores>0.90)]\n",
        "\n",
        "  df_person = df_person.append(t)\n",
        "  #p = p+1\n",
        "  #if p%100==0:\n",
        "    #print(p)\n",
        "  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wQHA7MhtK7O5"
      },
      "outputs": [],
      "source": [
        "#df_person.head()\n",
        "#final_df.iloc[0]['Image_name']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Q1yNNCYELbLU"
      },
      "outputs": [],
      "source": [
        "p=0\n",
        "ext_features = []\n",
        "\n",
        "for index,row in df_person.iterrows():\n",
        "  img = cv2.imread(img_path+\"/\"+row['Image_name'])\n",
        "\n",
        "  box = torch.Tensor(row[\"boxes\"]).detach().cpu().numpy()\n",
        "  (sX, sY, lX, lY) = box.astype(\"int\")\n",
        "  person_detect = img[sY:lY,sX:lX]\n",
        "  person_detect = cv2.resize(person_detect,(100,100))\n",
        "\n",
        "  person_detect = cv2.cvtColor(person_detect, cv2.COLOR_BGR2RGB)\n",
        "  person_detect= person_detect.transpose((2, 0, 1))\n",
        "  person_detect = np.expand_dims(person_detect, axis=0)\n",
        "  person_detect = person_detect / 255.0\n",
        "  person_detect = torch.FloatTensor(person_detect)\n",
        "  \n",
        "  print(person_detect)\n",
        "\n",
        "  image, _= model.transform(person_detect, None)\n",
        "  features = model.backbone(image.tensors)['pool']\n",
        "  ext_features.append(features.detach().cpu().numpy()[0])\n",
        "  p = p+1\n",
        "  if p%100==0:\n",
        "    print(p)\n",
        "df_person['object_feature_tensor'] = ext_features"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8tr7VavqLbhp"
      },
      "outputs": [],
      "source": [
        "df_person.head(20)\n",
        "\n",
        "df_person['ID'] = df_person.index.to_list()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-5VYrwLiO4cN"
      },
      "source": [
        "**EXECUTING SIMILARITY SEARCH** "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "z7hinq186xMx"
      },
      "outputs": [],
      "source": [
        "def calculate_similarity(v1, v2):\n",
        " return 1 - spatial.distance.cosine(v1, v2)\n",
        "\n",
        "query_list = [500,1264,5264,8000,11528,16000,19160]\n",
        "v=dict()\n",
        "for i in query_list:\n",
        "  t_f = []\n",
        "  t_df = df_person.copy()\n",
        "  feat_tesn = torch.FloatTensor(df_person['object_feature_tensor'].iloc[i].flatten())\n",
        "  for index,row in df_person.iterrows():\n",
        "    if len(str(row['object_feature_tensor']))!=1:\n",
        "      t_f.append(calculate_similarity(feat_tesn,torch.FloatTensor(row['object_feature_tensor'].flatten())))\n",
        "    else:\n",
        "      t_f.append(0)\n",
        "\n",
        "  df_person['similarity'] = t_f\n",
        "  t_df = df_person\n",
        "  t_df.sort_values(by = 'similarity',ascending = False,inplace = True)\n",
        "  print(i,t_df.head(10)['ID'].unique())\n",
        "  v[i] = t_df.head(10)['ID'].unique()\n",
        "\n",
        "  \"\"\"\n",
        "  for index,row in df_person.iterrows():\n",
        "    t_f.append(calculate_similarity(feat_tesn,torch.FloatTensor(row['object_feature_tensor'].flatten())))\n",
        "  df_person['similarity'] = t_f\n",
        "  #temp_df.sort_values(by = 'similarity', )\n",
        "\n",
        "df_person.sort_values(by = 'similarity').tail(10)\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mUsTWnR_6xY2"
      },
      "outputs": [],
      "source": [
        "def image_person(s):\n",
        "   im_path = img_path+\"/\"+df_person.iloc[11]['Image_name']\n",
        "   img = cv2.imread(im_path)\n",
        "   img_copy = img.copy()\n",
        "   img = cv2.resize(img,(500,500))\n",
        "   cv2_imshow(img)\n",
        "   box = torch.Tensor(df_person.iloc[11][\"boxes\"]).detach().cpu().numpy()\n",
        "   (sX, sY, lX, lY) = box.astype(\"int\")\n",
        "   person_detect = image[sY:lY,sX:lX]\n",
        "   person_detect = cv2.resize(person_detect,(100,100))\n",
        "   cv2_imshow(person_detect)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iLOOJ76Xdv0k"
      },
      "outputs": [],
      "source": [
        "q=1\n",
        "for i in query_list:\n",
        "  print('Query Image No:',q)\n",
        "  image_person(i)\n",
        "  q=q+1\n",
        "  for j in list(v[i]):\n",
        "    image_person(j)\n",
        "     "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LeZ9uKfj7R6S"
      },
      "outputs": [],
      "source": [
        "calculate_similarity(torch.FloatTensor(df_person['object_feature_tensor'].iloc[0].flatten()),torch.FloatTensor(df_person['object_feature_tensor'].iloc[20].flatten()))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Y--LzoSF7SF6"
      },
      "outputs": [],
      "source": [
        "torch.nn.CosineSimilarity(dim=0)(torch.FloatTensor(df_person['object_feature_tensor'].iloc[0]),torch.FloatTensor(df_person['object_feature_tensor'].iloc[15]))"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}